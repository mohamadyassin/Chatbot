{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Chatbots Fundamentals\n",
    "### Mohamad Yassin\n",
    "#### 09/20/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook introduces the fundamental techniques for building coversational chatbots. It can serve as a reference for building chatbot applications or models. The content will be split into three steps:\n",
    "\n",
    "1. An Introduction into functions and techniques, including: respond() function, responses dictionary, random responses, response rules, users templates, regular expressions patterns, replacing pronous, and defining intents. \n",
    "\n",
    "2. A quick overview of SpaCy's English model to create word/sentence vectors, calculate semantic cosine similarity, extract entities, and dependacny parsing. Introduction into predective machine learning with scikit-learn. \n",
    "\n",
    "3. A demonstration of: training an interpreter to extract intents and entities by using rasaNLU's predefined spacy-sklean pipeline with a set of training data, connecting the chatbot to a SQL database to take actions, running SQL queries with Python, and capturing negations in a sentence. \n",
    "\n",
    "4. An Implementation of a state-machine chatbot that can order coffee and chit-chat with the users. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The sample datasets and database can be found on my github: https://github.com/mohamadyassin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First things first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import what's neccessary \n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import sqlite3\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from rasa_nlu.config import RasaNLUModelConfig, DEFAULT_CONFIG\n",
    "from rasa_nlu.model import Trainer, TrainingData\n",
    "from rasa_nlu.model import Interpreter\n",
    "from rasa_nlu import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introductory Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's  begin by defining user templates, and the functions respond() and send_message(). This bot can repeat the user's message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : hello\n",
      "BOT : I can hear you! You said: hello\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create templates\n",
    "bot_template = \"BOT : {0}\"\n",
    "user_template = \"USER : {0}\"\n",
    "\n",
    "\n",
    "# Define a function that responds to a user's message: respond\n",
    "def respond(message):\n",
    "    # Concatenate the user's message to the end of a standard bot respone\n",
    "    bot_message = \"I can hear you! You said: \" + message\n",
    "    # Return the result\n",
    "    return bot_message\n",
    "\n",
    "\n",
    "# Define a function that sends a message to the bot: send_message\n",
    "def send_message(message):\n",
    "    # Print user_template including the user_message\n",
    "    print(user_template.format(message))\n",
    "    # Get the bot's response to the message\n",
    "    response = respond(message)\n",
    "    # Print the bot template including the bot's response.\n",
    "    print(bot_template.format(response))\n",
    "\n",
    "# Send a message to the bot\n",
    "send_message(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a dictionary of responses with two variables in order to define a respond function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the weather is cloudy\n",
      "my name is Greg\n"
     ]
    }
   ],
   "source": [
    "# Define variables\n",
    "name = \"Greg\"\n",
    "weather = \"cloudy\"\n",
    "\n",
    "# Define a dictionary with the predefined responses\n",
    "responses = {\n",
    "  \"what's your name?\": \"my name is {0}\".format(name),\n",
    "  \"what's today's weather?\": \"the weather is {0}\".format(weather),\n",
    "  \"default\": \"default message\"\n",
    "}\n",
    "\n",
    "# Return the matching response if there is one, default otherwise\n",
    "def respond(message):\n",
    "    # Check if the message is in the responses\n",
    "    if message in responses:\n",
    "        # Return the matching message\n",
    "        bot_message = responses[message]\n",
    "    else:\n",
    "        # Return the \"default\" message\n",
    "        bot_message = responses[\"default\"]\n",
    "    return bot_message\n",
    "\n",
    "# Test our function\n",
    "print(respond(\"what's today's weather?\"))\n",
    "print(respond(\"what's your name?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually users interact with the bot on a recurrent basis. To create a better personality to our bot, we can define mutiple answers to each response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the weather is sunny\n",
      "it's sunny today\n",
      "it's sunny today\n",
      "they call me Greg\n",
      "my name is Greg\n",
      "I go by Greg\n"
     ]
    }
   ],
   "source": [
    "# Define variables\n",
    "name = \"Greg\"\n",
    "weather = \"sunny\"\n",
    "\n",
    "# Define a dictionary containing a list of responses for each message\n",
    "responses = {\n",
    "  \"what's your name?\": [\n",
    "      \"my name is {0}\".format(name),\n",
    "      \"they call me {0}\".format(name),\n",
    "      \"I go by {0}\".format(name)\n",
    "   ],\n",
    "  \"what's today's weather?\": [\n",
    "      \"the weather is {0}\".format(weather),\n",
    "      \"it's {0} today\".format(weather)\n",
    "    ],\n",
    "  \"default\": [\"default message\"]\n",
    "}\n",
    "\n",
    "# Use random.choice() to choose a matching response\n",
    "def respond(message):\n",
    "    # Check if the message is in the responses\n",
    "    if message in responses:\n",
    "        # Return a random matching response\n",
    "        bot_message = random.choice(responses[message])\n",
    "    else:\n",
    "        # Return a random \"default\" response\n",
    "        bot_message = random.choice(responses[\"default\"])\n",
    "    return bot_message\n",
    "\n",
    "# Test our function\n",
    "print(respond(\"what's today's weather?\"))\n",
    "print(respond(\"what's today's weather?\"))\n",
    "print(respond(\"what's today's weather?\"))\n",
    "print(respond(\"what's your name?\"))\n",
    "print(respond(\"what's your name?\"))\n",
    "print(respond(\"what's your name?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a responses dictionary then choose a random answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know :(\n",
      "oh wow!\n"
     ]
    }
   ],
   "source": [
    "# Define responses\n",
    "responses = {'question': [\"I don't know :(\", 'you tell me!'],\n",
    " 'statement': ['tell me more!',\n",
    "  'why do you think that?',\n",
    "  'how long have you felt this way?',\n",
    "  'I find that extremely interesting',\n",
    "  'can you back that up?',\n",
    "  'oh wow!',\n",
    "  ':)']}\n",
    "\n",
    "# Classify as question if it ends wih '?'\n",
    "def respond(message):\n",
    "    # Check for a question mark\n",
    "    if message.endswith('?'):\n",
    "        # Return a random question\n",
    "        return random.choice(responses[\"question\"])\n",
    "    # Return a random statement\n",
    "    return random.choice(responses[\"statement\"])\n",
    "\n",
    "# Test our function\n",
    "print(respond(\"how can I find the bathroom?\"))\n",
    "print(respond(\"this is a really cool bot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's take our chit-cat bot one step further with Regular expressions (regex). Regex are a powerful tool that allows us to search pattens in a text. It also permits high degree of flexibility when defining repsponses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you think I would forget your last birthday\n",
      "Really--if I can eat apples\n",
      "default\n"
     ]
    }
   ],
   "source": [
    "# Define rules of patterns and responses lists\n",
    "rules = {\n",
    "    #1\n",
    "    'I want (.*)':     #the regex '.*' returns the rest of sentence\n",
    "         ['What would it mean if you got {0}',\n",
    "  'Why do you want {0}',\n",
    "  \"What's stopping you from getting {0}\"],\n",
    "    #2\n",
    " 'do you remember (.*)': \n",
    "         ['Did you think I would forget {0}',\n",
    "  \"Why haven't you been able to forget {0}\",\n",
    "  'What about {0}',\n",
    "  'Yes .. and?'],\n",
    "    #3\n",
    " 'do you think (.*)': \n",
    "         ['if {0}? Absolutely.', 'No chance'],\n",
    "    #4\n",
    " 'if (.*)': \n",
    "         [\"Do you really think it's likely that {0}\",\n",
    "  'Do you wish that {0}',\n",
    "  'What do you think about {0}',\n",
    "  'Really--if {0}']\n",
    "}\n",
    "\n",
    "# Define match_rule()\n",
    "def match_rule(rules, message):\n",
    "    response, phrase = \"default\", None\n",
    "\n",
    "    # Iterate over the rules dictionary\n",
    "    for pattern, responses in rules.items():\n",
    "        # Create a match object\n",
    "        match = re.search(pattern, message)\n",
    "        if match is not None:\n",
    "            # Choose a random response\n",
    "            response = random.choice(responses)\n",
    "            if '{0}' in response:\n",
    "                phrase = match.group(1)\n",
    "    # Return the response and phrase\n",
    "    return response.format(replace_pronouns(phrase))\n",
    "\n",
    "# Test match_rule\n",
    "print(match_rule(rules, \"do you remember your last birthday\"))\n",
    "print(match_rule(rules, \"do you know if I can eat apples\"))\n",
    "print(match_rule(rules, \"do you wish that the weather is sunny year-round?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's something funny about our bot's responses. It returned the wrong prounouns. Let's see if we replace pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what about my last birthday\n",
      "do you really think it's likely that she likes you?\n",
      "default\n"
     ]
    }
   ],
   "source": [
    "# Define replace_pronouns()\n",
    "def replace_pronouns(message):\n",
    "\n",
    "    message = message.lower()\n",
    "    if 'me' in message:\n",
    "        # Replace 'me' with 'you'\n",
    "        return re.sub('me','you', message)\n",
    "    if 'my' in message:\n",
    "        # Replace 'my' with 'your'\n",
    "        return re.sub('my','your', message)\n",
    "    if 'your' in message:\n",
    "        # Replace 'your' with 'my'\n",
    "        return re.sub('your','my', message)\n",
    "    if 'you' in message:\n",
    "        # Replace 'you' with 'me'\n",
    "        return re.sub('you','me',message)\n",
    "\n",
    "    return message\n",
    "\n",
    "\n",
    "# Define match_rule()\n",
    "def match_rule(rules, message):\n",
    "    response, phrase = \"default\", None\n",
    "    \n",
    "\n",
    "    # Iterate over the rules dictionary\n",
    "    for pattern, responses in rules.items():\n",
    "        # Create a match object\n",
    "        match = re.search(pattern, message)\n",
    "        if match is not None:\n",
    "            # Choose a random response\n",
    "            response = random.choice(responses)\n",
    "            if '{0}' in response:\n",
    "                phrase = match.group(1)\n",
    "    # Return the response and phrase\n",
    "    return replace_pronouns(response.format(phrase))\n",
    "\n",
    "# Test match_rule\n",
    "print(match_rule(rules, \"do you remember your last birthday\"))\n",
    "print(match_rule(rules, \"do you know if she likes me?\"))\n",
    "print(match_rule(rules, \"do you wish that the weather is sunny year-round?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's use regex to define a function that finds names in a sentence. We will use keywords and patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : my name is David Copperfield\n",
      "BOT : Hello, David Copperfield!\n",
      "USER : call me Mohamad\n",
      "BOT : Hello, Mohamad!\n",
      "USER : What's going on?\n",
      "BOT : Hi there!\n"
     ]
    }
   ],
   "source": [
    "# Define find_name()\n",
    "def find_name(message):\n",
    "    name = None\n",
    "    # Create a pattern for checking if the keywords occur\n",
    "    name_keyword = re.compile(r\"name|call\")\n",
    "    # Create a pattern for finding capitalized words\n",
    "    name_pattern = re.compile(r\"[A-Z]{1}[a-z]*\")\n",
    "    if name_keyword.search(message):\n",
    "        # Get the matching words in the string\n",
    "        name_words = name_pattern.findall(message)\n",
    "        if len(name_words) > 0:\n",
    "            # Return the name if the keywords are present\n",
    "            name = ' '.join(name_words)\n",
    "    return name\n",
    "\n",
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Find the name\n",
    "    name = find_name(message)\n",
    "    if name is None:\n",
    "        return \"Hi there!\"\n",
    "    else:\n",
    "        return \"Hello, {0}!\".format(name)\n",
    "\n",
    "\n",
    "# Define a function that sends a user's message\n",
    "def send_message(message):\n",
    "    print(user_template.format(message))\n",
    "    response = respond(message)\n",
    "    print(bot_template.format(response))\n",
    "\n",
    "\n",
    "# Send messages\n",
    "send_message(\"my name is David Copperfield\")\n",
    "send_message(\"call me Mohamad\")\n",
    "send_message(\"What's going on?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order for our bot to take real-world actions, we have to define intents. Let's take a quick look at a function that will allow us to find search intent in a message with regex. We will first define patterns and responses. Then we will define functions that can match the intent then respond to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'greet': re.compile('hello|hi|hey'), 'goodbye': re.compile('bye|farewell'), 'thankyou': re.compile('thank|thx')}\n"
     ]
    }
   ],
   "source": [
    "# Define variations of the same intent\n",
    "intents = {'greet': ['hello', 'hi', 'hey'],\n",
    "            'goodbye': ['bye', 'farewell'],\n",
    "            'thankyou': ['thank', 'thx']}\n",
    "\n",
    "#Define responses to intents\n",
    "responses = {'default': 'default message', \n",
    " 'goodbye': 'goodbye for now',\n",
    " 'greet': 'Hello you! :)',\n",
    " 'thankyou': 'you are very welcome'}\n",
    "\n",
    "# Instantiate an empty dictionary\n",
    "patterns = {}\n",
    "\n",
    "\n",
    "# Iterate over the keywords dictionary \n",
    "for intent, keys in intents.items():\n",
    "    # Create regular expressions and compile them into pattern objects\n",
    "    patterns[intent] = re.compile('|'.join(keys))\n",
    "\n",
    "\n",
    "# Now we have our patterns with variations ready for regex\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : hello!\n",
      "BOT : Hello you! :)\n",
      "USER : bye byeee\n",
      "BOT : goodbye for now\n",
      "USER : thanks very much!\n",
      "BOT : you are very welcome\n"
     ]
    }
   ],
   "source": [
    "# Define a function to find the intent of a message\n",
    "def match_intent(message):\n",
    "    matched_intent = None\n",
    "    # Iterate over items in patterns dicitionary\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message\n",
    "        if pattern.search(message):\n",
    "            matched_intent = intent\n",
    "    return matched_intent\n",
    "\n",
    "# Define a respond function\n",
    "def respond(message):\n",
    "    # Call the match_intent function\n",
    "    intent = match_intent(message)\n",
    "    # Fall back to the default response\n",
    "    key = \"default\"\n",
    "    if intent in responses:\n",
    "        key = intent\n",
    "    return responses[key]\n",
    "\n",
    "\n",
    "# Send messages\n",
    "send_message(\"hello!\")\n",
    "send_message(\"bye byeee\")\n",
    "send_message(\"thanks very much!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: SpaCy and Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by importing SpaCy's English model. We use the meduim-size model that has to be manually downloaded into our environment. Similarity is calculated using the cosine function. So we are measuring the degree of similiarty between tokens or ducements. A similarity of 1 means that both are in the same direction. 0 is perpendicular. And -1 is opposite directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will load the default en model\n",
    "nlp = spacy.load('en_core_web_md')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity betwen cat and can:  0.30165289379772614\n",
      "similarity betwen cat and dog:  0.8016854705531046\n",
      "similarity betwen cat and monkey:  0.5351812775125145\n"
     ]
    }
   ],
   "source": [
    "# Test semantic similarity \n",
    "doc = nlp('cat')\n",
    "print(\"similarity betwen cat and can: \", doc.similarity(nlp('can')))\n",
    "print(\"similarity betwen cat and dog: \", doc.similarity(nlp('dog')))\n",
    "print(\"similarity betwen cat and monkey: \", doc.similarity(nlp('monkey')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demonstration, we use the medium-size model which contains 300 unique tokens for each vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check vectors length \n",
    "nlp.vocab.vectors_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset which consists of sentences and their respective intents in order train a model on predicting intetns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 4977\n",
      "        atis_flight  \\\n",
      "0       atis_flight   \n",
      "1  atis_flight_time   \n",
      "2      atis_airfare   \n",
      "3      atis_airfare   \n",
      "4       atis_flight   \n",
      "\n",
      "   i want to fly from boston at 838 am and arrive in denver at 1110 in the morning  \n",
      "0   what flights are available from pittsburgh to...                                \n",
      "1   what is the arrival time in san francisco for...                                \n",
      "2            cheapest airfare from tacoma to orlando                                \n",
      "3   round trip fares from pittsburgh to philadelp...                                \n",
      "4   i need a flight tomorrow from columbus to min...                                \n"
     ]
    }
   ],
   "source": [
    "# Read atis intent as a dataframe\n",
    "df = pd.read_csv('atis/atis_intents.csv')\n",
    "\n",
    "# Inspect the dataframe\n",
    "print(\"number of samples: {}\".format(len(df)))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique labels:  22\n"
     ]
    }
   ],
   "source": [
    "# Identify the number of unique labels\n",
    "print(\"number of unique labels: \", len(df.iloc[:,0].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atis_flight                                 0.736387\n",
       "atis_airfare                                0.084991\n",
       "atis_ground_service                         0.051236\n",
       "atis_airline                                0.031545\n",
       "atis_abbreviation                           0.029536\n",
       "atis_aircraft                               0.016275\n",
       "atis_flight_time                            0.010850\n",
       "atis_quantity                               0.010247\n",
       "atis_flight#atis_airfare                    0.004219\n",
       "atis_distance                               0.004018\n",
       "atis_airport                                0.004018\n",
       "atis_city                                   0.003818\n",
       "atis_ground_fare                            0.003617\n",
       "atis_capacity                               0.003215\n",
       "atis_flight_no                              0.002411\n",
       "atis_restriction                            0.001206\n",
       "atis_meal                                   0.001206\n",
       "atis_airline#atis_flight_no                 0.000402\n",
       "atis_airfare#atis_flight_time               0.000201\n",
       "atis_ground_service#atis_ground_fare        0.000201\n",
       "atis_cheapest                               0.000201\n",
       "atis_aircraft#atis_flight#atis_flight_no    0.000201\n",
       "Name: atis_flight, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a closer look at the intent labels\n",
    "df.iloc[:,0].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the first 5 labels represent more than 93% of the samples, we will drop the bottom 18 labels because they will not contribute to our classification model. This way our classifier has a better chance to predict the correct labels. This is an important note to take when choosing training data for real-life models. \n",
    "\n",
    "We can better transform our data by dealing with integer labels so we will use sklearn's label encoder to get the job done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       12\n",
       "1       15\n",
       "2        3\n",
       "3        3\n",
       "4       12\n",
       "        ..\n",
       "4972     3\n",
       "4973    12\n",
       "4974     5\n",
       "4975    12\n",
       "4976    12\n",
       "Name: atis_flight, Length: 4977, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a LabelEncoder then transform our labels column\n",
    "le = LabelEncoder()\n",
    "df.iloc[:,0] = le.fit_transform(df.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    0.736387\n",
       "3     0.084991\n",
       "17    0.051236\n",
       "5     0.031545\n",
       "0     0.029536\n",
       "1     0.016275\n",
       "15    0.010850\n",
       "20    0.010247\n",
       "13    0.004219\n",
       "7     0.004018\n",
       "11    0.004018\n",
       "10    0.003818\n",
       "16    0.003617\n",
       "8     0.003215\n",
       "14    0.002411\n",
       "19    0.001206\n",
       "21    0.001206\n",
       "6     0.000402\n",
       "4     0.000201\n",
       "18    0.000201\n",
       "2     0.000201\n",
       "9     0.000201\n",
       "Name: atis_flight, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out the top 5 intents we want to keep\n",
    "df.iloc[:,0].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to quickly select the top five labels, we will set the integer labels as an index then select the desired values based on the value caounts above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the labels as index and select samples\n",
    "df = df.set_index(df.iloc[:,0]).loc[(12,3,17,5,0),:]\n",
    "# Drop the index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atis_flight</th>\n",
       "      <th>i want to fly from boston at 838 am and arrive in denver at 1110 in the morning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>what flights are available from pittsburgh to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>i need a flight tomorrow from columbus to min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>show me the flights from pittsburgh to los an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>all flights from boston to washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>show me the flights from dallas to san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>0</td>\n",
       "      <td>what does fare code qo mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4643</th>\n",
       "      <td>0</td>\n",
       "      <td>what does ewr mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4644</th>\n",
       "      <td>0</td>\n",
       "      <td>what is fare code h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4645</th>\n",
       "      <td>0</td>\n",
       "      <td>what does the fare code qw mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>0</td>\n",
       "      <td>what does fare code qo mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4647 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      atis_flight  \\\n",
       "0              12   \n",
       "1              12   \n",
       "2              12   \n",
       "3              12   \n",
       "4              12   \n",
       "...           ...   \n",
       "4642            0   \n",
       "4643            0   \n",
       "4644            0   \n",
       "4645            0   \n",
       "4646            0   \n",
       "\n",
       "      i want to fly from boston at 838 am and arrive in denver at 1110 in the morning  \n",
       "0      what flights are available from pittsburgh to...                                \n",
       "1      i need a flight tomorrow from columbus to min...                                \n",
       "2      show me the flights from pittsburgh to los an...                                \n",
       "3                 all flights from boston to washington                                \n",
       "4      show me the flights from dallas to san francisco                                \n",
       "...                                                 ...                                \n",
       "4642                        what does fare code qo mean                                \n",
       "4643                                 what does ewr mean                                \n",
       "4644                                what is fare code h                                \n",
       "4645                    what does the fare code qw mean                                \n",
       "4646                        what does fare code qo mean                                \n",
       "\n",
       "[4647 rows x 2 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect the dataframe \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atis_flight                                                                         0\n",
       " i want to fly from boston at 838 am and arrive in denver at 1110 in the morning    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check for any null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the dataframe ready to use. We will begin with the cosine similarity function from sklearn. In order to do so, we first create word vectors for each of our sentences with SpaCy's English medium-size model. This is a simple and very easy to use method that can be useful sometimes for tasks such a recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features and labels\n",
    "X = np.array(df.iloc[:,1])\n",
    "y = np.array(df.iloc[:,0])\n",
    "\n",
    "# Create a shape\n",
    "X_train_shape = (\n",
    "    len(X),\n",
    "    nlp.vocab.vectors_length)\n",
    "\n",
    "# Create zeros array\n",
    "X_train_vector = np.zeros(X_train_shape)\n",
    "\n",
    "# Loop over array with vector for each sentence\n",
    "for i, sentence in enumerate(X):\n",
    "    X_train_vector[i,:] = nlp(sentence).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted intent:   atis_flight\n"
     ]
    }
   ],
   "source": [
    "# Test message\n",
    "test_mesage = \"I would like to find a nonstop flight from georgia to Washingotn DC\"\n",
    "\n",
    "# Create a vector from nlp\n",
    "test_x = nlp(test_mesage).vector\n",
    "\n",
    "# Calculate a list of scores with list comrehension\n",
    "scores = [\n",
    "    cosine_similarity(X_train_vector[i,:].reshape(-1,1), test_x.reshape(-1,1)).mean()\n",
    "    for i in range(len(X))\n",
    "]\n",
    "# Search the highest score and match it agaisnt its labels index\n",
    "test_score = y[np.argmax(scores)]\n",
    "\n",
    "# Use a dictionary to interpret the score\n",
    "score_dict = {12: \"atis_flight\",\n",
    "             3: \"atis_airfare\",\n",
    "             17: \"atis_ground_service\",\n",
    "             5: \"atis_airline \",\n",
    "             0: \"atis_abbreviation\"}\n",
    "\n",
    "print(\"predicted intent:   {}\".format(score_dict[test_score]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the same data to predict labeled intents by using a support vector classifier from sklearn. We begin by splitting the data then fitting the model, then we will count the number of correct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 441 correctly out of 465 test examples\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_vector,y,test_size=0.1,random_state=42)\n",
    "\n",
    "# Create a support vector classifier\n",
    "model = SVC(C=1, gamma='scale')\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Count the number of correct predictions\n",
    "n_correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        n_correct += 1\n",
    "\n",
    "print(\"Predicted {0} correctly out of {1} test examples\".format(n_correct, len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Rasa NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we'll define the configuration to our model then create a trainer out of it in order to create an interpreter and train it on our data. The interpreter will parse intents and entities from our sentences. We are using restaurants data for this purpose. Then we will connect to a local sample sql database that will allow us to test our bot's ability to take actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create args dictionary\n",
    "args = {\"pipeline\": \"spacy_sklearn\"}\n",
    "\n",
    "# Create a configuration and trainer\n",
    "config = RasaNLUModelConfig(configuration_values=args)\n",
    "trainer = Trainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "{'intent': {'name': 'restaurant_search', 'confidence': 0.8342435271519987}, 'entities': [{'start': 18, 'end': 25, 'value': 'mexican', 'entity': 'cuisine', 'confidence': 0.6231186599376848, 'extractor': 'CRFEntityExtractor'}, {'start': 44, 'end': 49, 'value': 'north', 'entity': 'location', 'confidence': 0.8386232722553214, 'extractor': 'CRFEntityExtractor'}], 'intent_ranking': [{'name': 'restaurant_search', 'confidence': 0.8342435271519987}, {'name': 'greet', 'confidence': 0.04127640804383251}, {'name': 'affirm', 'confidence': 0.03619636710182238}, {'name': 'chitchat/ask_weather', 'confidence': 0.03102607470749123}, {'name': 'chitchat/ask_name', 'confidence': 0.028698000180374494}, {'name': 'goodbye', 'confidence': 0.02855962281448071}], 'text': \"I'm looking for a Mexican restaurant in the North of town\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Load the training data\n",
    "training_data = load_data(\"training_data.json\")\n",
    "\n",
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# Test the interpreter\n",
    "print(interpreter.parse(\"I'm looking for a Mexican restaurant in the North of town\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted entities: {'cuisine': 'mexican', 'location': 'north'}\n"
     ]
    }
   ],
   "source": [
    "# Extract entities using the interpreter\n",
    "message = \"I'm looking for a Mexican restaurant in the North of town\"\n",
    "data = interpreter.parse(message)    #trained model\n",
    "\n",
    "#Save entities as key value pairs\n",
    "params = {}\n",
    "for ent in data[\"entities\"]:\n",
    "    params[ent['entity']] = ent['value'] #this should return price & location\n",
    "\n",
    "print(\"extracted entities: {}\".format(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we connect our sample database in order to have our bot start taking some real world actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hotel for Dogs', 'mid', 'east', 3),\n",
       " ('Hotel California', 'mid', 'north', 3),\n",
       " ('Grand Hotel', 'hi', 'south', 5),\n",
       " ('Cozy Cottage', 'lo', 'south', 2),\n",
       " (\"Ben's BnB\", 'hi', 'north', 4),\n",
       " ('The Grand', 'hi', 'west', 5),\n",
       " ('Central Rooms', 'mid', 'center', 3)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create connection\n",
    "conn = sqlite3.connect(\"hotels.db\")\n",
    "\n",
    "# Create a cursor to access db connection\n",
    "c = conn.cursor()\n",
    "\n",
    "# Execute a query\n",
    "c.execute(\"SELECT * FROM hotels\")\n",
    "\n",
    "# Get the results from the sursor\n",
    "c.fetchall()        # Returns a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract entities using the interpreter\n",
    "message = \"cheap hotel in the south\"\n",
    "data = interpreter.parse(message)    # Our trained model\n",
    "\n",
    "# Save entities as key value pairs\n",
    "params = {}\n",
    "for ent in data[\"entities\"]:\n",
    "    params[ent['entity']] = ent['value'] # This should return price & location\n",
    "\n",
    "# Here's a hard coded dict for the sake of trial\n",
    "params = {'location': 'south', 'price': 'lo'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how we construct our queries befor we actually use them in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cozy Cottage',)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract filters for later\n",
    "query = \"SELECT name FROM hotels\"\n",
    "filters = [\"{}=?\".format(k) for k in params.keys()]  # This returns extracted entities   \n",
    "\n",
    "# Define condition\n",
    "conditions = \" and \".join(filters)\n",
    "\n",
    "# Define final query\n",
    "final_q = \" WHERE \".join([query, conditions])\n",
    "\n",
    "# Define query params\n",
    "t = tuple(params.values())\n",
    "\n",
    "# Let's try it out!\n",
    "c.execute(final_q,t)\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the two steps above to build our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Cozy Cottage', 'lo', 'south', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Define find_hotels()\n",
    "def find_hotels(params):\n",
    "    # Create the base query\n",
    "    query = 'SELECT * FROM hotels'\n",
    "    # Add filter clauses for each of the parameters\n",
    "    if len(params) > 0:\n",
    "        filters = [\"{}=?\".format(k) for k in params]\n",
    "        query += \" WHERE \" + \" AND \".join(filters)\n",
    "    # Create the tuple of values\n",
    "    t = tuple(params.values())\n",
    "\n",
    "    # Open connection to DB\n",
    "    conn = sqlite3.connect(\"hotels.db\")\n",
    "    # Create a cursor\n",
    "    c = conn.cursor()\n",
    "    # Execute the query\n",
    "    c.execute(query, t)\n",
    "    # Return the results\n",
    "    return c.fetchall()\n",
    "\n",
    "\n",
    "# Create the dictionary of column names and values\n",
    "params = {\"location\":\"south\",\n",
    "    \"price\": \"lo\"}\n",
    "\n",
    "# Find the hotels that match the parameters\n",
    "print(find_hotels(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our chatbot to respond to the user with the results of the query. What happens if we run a query and get more than one result, multiple results, or no results at all? We can define the responses and function in the following manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what about [(\"Ben's BnB\",)]?\n"
     ]
    }
   ],
   "source": [
    "# How to return responses when we have 0 or >1 results\n",
    "responses = [\n",
    "    \"I'm sorry :( I couldn't fins anything like that\",\n",
    "    \"what about {}?\",\n",
    "    \"{} is one option, but I know others too :)\"\n",
    "]\n",
    "\n",
    "# Run a query\n",
    "results = c.execute(\"SELECT name FROM hotels WHERE location='north' and price='hi'\").fetchall()\n",
    "\n",
    "# Get the length\n",
    "len(results) \n",
    "\n",
    "# Define index\n",
    "index = min(len(results), len(responses)-1)\n",
    "\n",
    "# Index response\n",
    "responses[index]\n",
    "\n",
    "# Print response\n",
    "print(responses[index].format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotel California is one option, but I know others too :)\n"
     ]
    }
   ],
   "source": [
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Extract the entities\n",
    "    entities = interpreter.parse(message)[\"entities\"]\n",
    "    # Initialize an empty params dictionary\n",
    "    params = {}\n",
    "    # Fill the dictionary with entities\n",
    "    for ent in entities:\n",
    "        params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "\n",
    "    # Find hotels that match the dictionary\n",
    "    results = find_hotels(params)\n",
    "    # Get the names of the hotels and index of the response\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results),3)\n",
    "    # Select the nth element of the responses array\n",
    "    return responses[n].format(*names)\n",
    "\n",
    "print(respond(\"I want a hotel in the north of town\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having our chatbot detect negation could be a tricky task. One way to accomplish this by capturing the enteties that are preceeded by 'not' or 'n't'. However, this techniques will fail us with other forms of negation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negated entities: [sushi]\n",
      "other entities: [pizza]\n"
     ]
    }
   ],
   "source": [
    "# Capturing negations\n",
    "doc = nlp('not sushi, maybe pizza?')\n",
    "indicies = [1, 4]   #starting from the entity, ending at len+1\n",
    "\n",
    "ents, negated_ents = [], []  #initialize empty lists\n",
    "\n",
    "start = 0   #start from zero\n",
    "\n",
    "for i in indicies:\n",
    "    phrase = \"{}\".format(doc[start:i])\n",
    "    if \"not\" in phrase or \"n't\" in phrase:\n",
    "        negated_ents.append(doc[i])\n",
    "    else:\n",
    "        ents.append(doc[i])\n",
    "    start = i\n",
    "\n",
    "print(\"negated entities: {}\".format(negated_ents))\n",
    "print(\"other entities: {}\".format(ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the multiple answers techniques in a function then test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: I want an expensive hotel\n",
      "BOT: Hotel for Dogs is one option, but I know others too :)\n",
      "USER: in the north of town\n",
      "BOT: Hotel California or Ben's BnB would work!\n"
     ]
    }
   ],
   "source": [
    "# Define responses\n",
    "responses = [\"I'm sorry :( I couldn't find anything like that\",\n",
    " '{} is a great hotel!',\n",
    " '{} or {} would work!',\n",
    " '{} is one option, but I know others too :)']\n",
    "\n",
    "# Define a respond function, taking the message and existing params as input\n",
    "def respond(message, params):\n",
    "    # Extract the entities\n",
    "    entities = interpreter.parse(message)[\"entities\"]\n",
    "    # Fill the dictionary with entities\n",
    "    for ent in entities:\n",
    "        params[ent[\"entity\"]] = str(ent[\"value\"])\n",
    "\n",
    "    # Find the hotels\n",
    "    results = find_hotels(params)\n",
    "    names = [r[0] for r in results]\n",
    "    n = min(len(results), 3)\n",
    "    # Return the appropriate response\n",
    "    return responses[n].format(*names), params\n",
    "\n",
    "\n",
    "# Initialize params dictionary\n",
    "params = {}\n",
    "\n",
    "# Pass the messages to the bot\n",
    "for message in [\"I want an expensive hotel\", \"in the north of town\"]:\n",
    "    print(\"USER: {}\".format(message))\n",
    "    response, params = respond(message, params)\n",
    "    print(\"BOT: {}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: State Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two main components of a state machine are: states and policy rules. We define the states according to the workflow of the app. Policy rules are defined as a dictionary of tuples of keys and values. The keys include the state and intent, and the values include the state and response. The state is selected after the bot detects an intent (with the trained interpreter) and the response is sent accordingly. Usually the state defaults to a certain value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : I'd like to become a professional dancer\n",
      "BOT : I'm sorry - I'm not sure how to help you\n",
      "USER : well then I'd like to order some coffee\n",
      "BOT : ok, Colombian or Kenyan?\n",
      "USER : my favourite animal is a zebra\n",
      "BOT : I'm sorry - would you like Colombian or Kenyan?\n",
      "USER : kenyan\n",
      "BOT : perfect, the beans are on their way!\n"
     ]
    }
   ],
   "source": [
    "# Define the three states\n",
    "INIT = 0\n",
    "CHOOSE_COFFEE = 1\n",
    "ORDERED = 2\n",
    "\n",
    "# Define the policy rules\n",
    "policy = {\n",
    "    (INIT, \"order\"): (CHOOSE_COFFEE, \"ok, Colombian or Kenyan?\"),\n",
    "    (INIT, \"none\"): (INIT, \"I'm sorry - I'm not sure how to help you\"),\n",
    "    (CHOOSE_COFFEE, \"specify_coffee\"): (ORDERED, \"perfect, the beans are on their way!\"),\n",
    "    (CHOOSE_COFFEE, \"none\"): (CHOOSE_COFFEE, \"I'm sorry - would you like Colombian or Kenyan?\"),\n",
    "}\n",
    "\n",
    "# Define a function that interprets the intent\n",
    "def interpret(message):\n",
    "    msg = message.lower()\n",
    "    if 'order' in msg:\n",
    "        return 'order'\n",
    "    if 'kenyan' in msg or 'colombian' in msg:\n",
    "        return 'specify_coffee'\n",
    "    return 'none'\n",
    "\n",
    "# Initial state is usually predefined\n",
    "state = INIT\n",
    "# Define a respond function\n",
    "def respond(policy, state, message):\n",
    "    (new_state, response) = policy[(state, interpret(message))]\n",
    "    return new_state, response\n",
    "\n",
    "# Define a function that sends a message\n",
    "def send_message(policy, state, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    new_state, response = respond(policy, state, message)\n",
    "    print(\"BOT : {}\".format(response))\n",
    "    return new_state\n",
    "\n",
    "\n",
    "# Create the list of messages\n",
    "messages = [ \"I'd like to become a professional dancer\",\n",
    "    \"well then I'd like to order some coffee\",\n",
    "    \"my favourite animal is a zebra\",\n",
    "    \"kenyan\"]\n",
    "\n",
    "# Call send_message() for each message\n",
    "state = INIT\n",
    "for message in messages:\n",
    "    state = send_message(policy, state, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually users ask the explainatory questions, so it can be helpful to add such an intent to our policy rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : what can you do for me?\n",
      "BOT : I'm a bot to help you order coffee beans\n",
      "USER : well then I'd like to order some coffee\n",
      "BOT : ok, Colombian or Kenyan?\n",
      "USER : what do you mean by that?\n",
      "BOT : We have two kinds of coffee beans - the Kenyan ones make a slightly sweeter coffee, and cost $6. The Brazilian beans make a nutty coffee and cost $5.\n",
      "USER : kenyan\n",
      "BOT : perfect, the beans are on their way!\n"
     ]
    }
   ],
   "source": [
    "# Define the policy rules dictionary\n",
    "policy_rules = {\n",
    "    (INIT, \"ask_explanation\"): (INIT, \"I'm a bot to help you order coffee beans\"),\n",
    "    (INIT, \"order\"): (CHOOSE_COFFEE, \"ok, Colombian or Kenyan?\"),\n",
    "    (CHOOSE_COFFEE, \"specify_coffee\"): (ORDERED, \"perfect, the beans are on their way!\"),\n",
    "    (CHOOSE_COFFEE, \"ask_explanation\"): (CHOOSE_COFFEE, \n",
    "                                         \"We have two kinds of coffee beans - the Kenyan ones make a slightly sweeter coffee, and cost $6. The Brazilian beans make a nutty coffee and cost $5.\")\n",
    "}\n",
    "\n",
    "# Define a function that interprets the intent\n",
    "def interpret(message):\n",
    "    msg = message.lower()\n",
    "    if 'order' in msg:\n",
    "        return 'order'\n",
    "    if 'kenyan' in msg or 'colombian' in msg:\n",
    "        return 'specify_coffee'\n",
    "    if 'what' in msg:\n",
    "        return 'ask_explanation'\n",
    "    return 'none'\n",
    "\n",
    "# Initial state is usually predefined\n",
    "state = INIT\n",
    "\n",
    "# Define a respond function\n",
    "def respond(state, message):\n",
    "    (new_state, response) = policy_rules[(state, interpret(message))]\n",
    "    return new_state, response\n",
    "\n",
    "# Define a function that sends a message\n",
    "def send_message(state, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    new_state, response = respond(state, message)\n",
    "    print(\"BOT : {}\".format(response))\n",
    "    return new_state\n",
    "\n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    state = INIT\n",
    "    for msg in messages:\n",
    "        state = send_message(state, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"what can you do for me?\",\n",
    "    \"well then I'd like to order some coffee\",\n",
    "    \"what do you mean by that?\",\n",
    "    \"kenyan\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the workflow or process require an authentication or other state that can remain pending until the user identifies the conditions. Using a pending state can be useful for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : I'd like to order some coffee\n",
      "BOT : you'll have to log in first, what's your phone number?\n",
      "USER : 555-1234\n",
      "BOT : perfect, welcome back!\n",
      "BOT : would you like Colombian or Kenyan?\n",
      "USER : kenyan\n",
      "BOT : perfect, the beans are on their way!\n",
      "BOT : would you like Colombian or Kenyan?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the states\n",
    "INIT=0\n",
    "AUTHED=1\n",
    "CHOOSE_COFFEE=2\n",
    "ORDERED=3\n",
    "\n",
    "# Define the policy rules\n",
    "policy_rules = {\n",
    "    (INIT, \"order\"): (INIT, \"you'll have to log in first, what's your phone number?\", AUTHED),\n",
    "    (INIT, \"number\"): (AUTHED, \"perfect, welcome back!\", None),\n",
    "    (AUTHED, \"order\"): (CHOOSE_COFFEE, \"would you like Colombian or Kenyan?\", None),\n",
    "    (CHOOSE_COFFEE, \"specify_coffee\"): (ORDERED, \"perfect, the beans are on their way!\", None)\n",
    "}\n",
    "\n",
    "# Defind the interpret() function\n",
    "def interpret(message):\n",
    "    msg = message.lower()\n",
    "    if 'order' in msg:\n",
    "        return 'order'\n",
    "    if 'kenyan' in msg or 'colombian' in msg:\n",
    "        return 'specify_coffee'\n",
    "    if any([d in msg for d in string.digits]):\n",
    "        return 'number'\n",
    "    return 'none'\n",
    "\n",
    "# Defind the send_message() function\n",
    "def send_message(state, pending, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    new_state, response, pending_state = policy_rules[(state, interpret(message))]\n",
    "    print(\"BOT : {}\".format(response))\n",
    "    if pending is not None:\n",
    "        new_state, response, pending_state = policy_rules[pending]\n",
    "        print(\"BOT : {}\".format(response))\n",
    "    if pending_state is not None:\n",
    "        pending = (pending_state, interpret(message))\n",
    "    return new_state, pending\n",
    "\n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    state = INIT\n",
    "    pending = None\n",
    "    for msg in messages:\n",
    "        state, pending = send_message(state, pending, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\"I'd like to order some coffee\",\n",
    "    \"555-1234\",\n",
    "    \"kenyan\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define a bot that can chit-chat and order coffee at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : I'd like to order some coffee\n",
      "BOT : you'll have to log in first, what's your phone number?\n",
      "USER : 555-12345\n",
      "BOT : perfect, welcome back!\n",
      "BOT : would you like Colombian or Kenyan?\n",
      "USER : do you remember when I ordered 1000 kilos by accident?\n",
      "BOT : Yes .. and?\n",
      "USER : kenyan\n",
      "BOT : perfect, the beans are on their way!\n"
     ]
    }
   ],
   "source": [
    "eliza_rules = {'I want (.*)': ['What would it mean if you got {0}',\n",
    "  'Why do you want {0}',\n",
    "  \"What's stopping you from getting {0}\"],\n",
    " 'do you remember (.*)': ['Did you think I would forget {0}',\n",
    "  \"Why haven't you been able to forget {0}\",\n",
    "  'What about {0}',\n",
    "  'Yes .. and?'],\n",
    " 'do you think (.*)': ['if {0}? Absolutely.', 'No chance'],\n",
    " 'if (.*)': [\"Do you really think it's likely that {0}\",\n",
    "  'Do you wish that {0}',\n",
    "  'What do you think about {0}',\n",
    "  'Really--if {0}']}\n",
    "\n",
    "# Define a function that matches chit-chat rules\n",
    "def match_rule(rules, message):\n",
    "    for pattern, responses in rules.items():\n",
    "        match = re.search(pattern, message)\n",
    "        if match is not None:\n",
    "            response = random.choice(responses)\n",
    "            var = match.group(1) if '{0}' in response else None\n",
    "            return response, var\n",
    "    return \"default\", None\n",
    "        \n",
    "# Define a function to replace pronouns\n",
    "def replace_pronouns(message):\n",
    "    message = message.lower()\n",
    "    if 'me' in message:\n",
    "        return re.sub('me', 'you', message)\n",
    "    if 'i' in message:\n",
    "        return re.sub('i', 'you', message)\n",
    "    elif 'my' in message:\n",
    "        return re.sub('my', 'your', message)\n",
    "    elif 'your' in message:\n",
    "        return re.sub('your', 'my', message)\n",
    "    elif 'you' in message:\n",
    "        return re.sub('you', 'me', message)\n",
    "    return message\n",
    "\n",
    "# Defind the interpret() function\n",
    "def interpret(message):\n",
    "    msg = message.lower()\n",
    "    if 'order' in msg:\n",
    "        return 'order'\n",
    "    if 'kenyan' in msg or 'colombian' in msg:\n",
    "        return 'specify_coffee'\n",
    "    if any([d in msg for d in string.digits]):\n",
    "            return 'number' \n",
    "    return 'none'\n",
    "\n",
    "# Define chitchat_response()\n",
    "def chitchat_response(message):\n",
    "    # Call match_rule()\n",
    "    response, var = match_rule(eliza_rules, message)\n",
    "    # Return none if response is \"default\"\n",
    "    if response == \"default\":\n",
    "        return None\n",
    "    if '{0}' in response:\n",
    "        # Replace the pronouns of phrase\n",
    "        var = replace_pronouns(var)\n",
    "        # Calculate the response\n",
    "        response = response.format(var)\n",
    "    return response\n",
    "\n",
    "# Define send_message()\n",
    "def send_message(state, pending, message):\n",
    "    print(\"USER : {}\".format(message))\n",
    "    response = chitchat_response(message)\n",
    "    if response is not None:\n",
    "        print(\"BOT : {}\".format(response))\n",
    "        return state, None\n",
    "\n",
    "    # Calculate the new_state, response, and pending_state\n",
    "    new_state, response, pending_state = policy_rules[(state, interpret(message))]\n",
    "    print(\"BOT : {}\".format(response))\n",
    "    if pending is not None:\n",
    "        new_state, response, pending_state = policy_rules[pending]\n",
    "        print(\"BOT : {}\".format(response))\n",
    "    if pending_state is not None:\n",
    "        pending = (pending_state, interpret(message))\n",
    "    return new_state, pending\n",
    "\n",
    "# Define send_messages()\n",
    "def send_messages(messages):\n",
    "    state = INIT\n",
    "    pending = None\n",
    "    for msg in messages:\n",
    "        state, pending = send_message(state, pending, msg)\n",
    "\n",
    "# Send the messages\n",
    "send_messages([\n",
    "    \"I'd like to order some coffee\",\n",
    "    \"555-12345\",\n",
    "    \"do you remember when I ordered 1000 kilos by accident?\",\n",
    "    \"kenyan\"\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
